{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2GhO8OlsaMd",
        "outputId": "80549355-db73-4180-961f-7edebed3b7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o4KP_chpmSF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers, preprocessing\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pyarrow.feather as feather\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout, BatchNormalization,LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MIuvGGf0Cod"
      },
      "outputs": [],
      "source": [
        "edf_path=\"/content/drive/MyDrive/temp2/signal_sync_EDF (\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40947232-85be-466c-ae54-4423be99e30f"
      },
      "outputs": [],
      "source": [
        "edf = pd.DataFrame()\n",
        "\n",
        "for i in range (2,24):\n",
        "  path = edf_path + str(i) + ').feather'\n",
        "  edf_temp = feather.read_table(path).to_pandas()\n",
        "  edf_temp['Patient'] = i\n",
        "  edf = pd.concat([edf, edf_temp.iloc[::100,:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4q0vFQyUA80"
      },
      "outputs": [],
      "source": [
        "y = np.array([ 49.21925595452256, 79.17007141080755, 31.33331048898331, 36.30885122410546, 70.04614242844697,\n",
        "              51.50981226076919, 24.066003807911994, 24.066003807911994, 44.145334434351774, 23.339089339271105,\n",
        "               56.37456501107244, 56.37456501107244, 39.90900644003716, 29.995583689091713, 33.02068965517241,\n",
        "               51.50981226076919, 22.309859154929576, 43.288490284005974, 61.88520676153185, 18.013110808499857,\n",
        "               40.34420652391435, 32.98709474346868\n",
        "               ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW2ccs8rTwdK"
      },
      "outputs": [],
      "source": [
        "max_length = edf.groupby('Patient')['SpO2'].count().max()\n",
        "X = [np.pad(edf[edf['Patient'] == patient]['SpO2'].values, (0, max_length - len(edf[edf['Patient'] == patient]))) for patient in edf['Patient'].unique()]\n",
        "X = np.array(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psm6PtmH8DYg"
      },
      "outputs": [],
      "source": [
        "X = np.expand_dims(X, axis=2)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KuRVHiG8HfY"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.set_random_seed(42)"
      ],
      "metadata": {
        "id": "4VrRvHWkdLaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xy-vVimhDRL"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv1D(32, 3, activation='relu', input_shape=(max_length, 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(64, 3, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb7Ng2J4UlFs"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, batch_size=6, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3hFgRjRU0As"
      },
      "outputs": [],
      "source": [
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test MAE: {mae}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "v2PViZHEupmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oV_Mnynh1lB"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model to disk\n",
        "filename = 'AHI_model_ML_0909.pkl'\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(model, file)\n"
      ],
      "metadata": {
        "id": "PTybwqs2lwVN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}